{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Project overview","text":""},{"location":"#what","title":"What","text":"<p>We are building a new typhoid immunity model with a continuous, time-varying correlate of protection and dose-dependent susceptibility.</p>"},{"location":"#why","title":"Why","text":"<p>Because typhoid immunity is interesting! The new Typhoid Conjugate Vaccine (TCV) seems to perform differently in different settings. Everywhere it's been trialed, the observed efficacy against blood-culture confirmed typhoid is around ~80% for the first two years, but while there is little evidence of waning in some settings \u2014 not yet reported in Nepal and statistically insignificant in Malawi \u2014 there is clear waning in Bangladesh and both lower observed efficacy and faster and city-dependent waning in Pakistan. In addition, there is some observed variation of waning by age, with younger children waning faster.</p> <p>These strong differences in vaccine effectiveness by setting and age indicate the need for bespoke vaccination strategies. To rationally design those strategies across settings \u2014 from hyper-endemic to solely at risk from importation \u2014 we need a model capable of explaining the observations and extrapolating from them.</p>"},{"location":"#how","title":"How","text":"<p>Prior work by IDM on poliovirus \u2014 another predominantly enteric pathogen transmitted via the fecal-oral route \u2014 found that epidemiological measures of immunity depend on both individual-level immune response and the typical size of pathogen doses acquired via transmission, and we built a model to capture that dynamic. Following the demonstration that a similar model framework was useful for COVID as well, we've developed a general formulation of the model and will be fitting it to typhoid for the first time in this project.</p> <p>We'll explain the model as we develop it using this blog and documentation. Until then, here are preview slides describing the approach. You can see that it is in the flavor of a PK/PD model common for drug development, but with some features I haven't seen implemented by others. For a technical introduction to PK/PD modeling, see these notes by Henrik Madsen).</p>"},{"location":"#when","title":"When","text":"<p>We hope to have useful results well before the WHO SAGE meeting on TCV schedule recommendations in October 2025. Initial deadline to de-risk the whole project is April 2025.</p>"},{"location":"#where","title":"Where","text":"<p>Developed at the Institute for Disease Modeling (IDM), a research institute within the Gates Foundation's Global Health Division.</p> <p>The Github repo is famulare/typhoid-immune-dynamics.</p>"},{"location":"#who","title":"Who","text":"<p>Technical project lead: Mike Famulare.</p> <p>Technical collaboration with: Kyra Grantz, Vince Buffalo, and Alicia Kraay.</p> <p>IDM Typhoid research and strategy lead: Jillian Gauld.</p>"},{"location":"about/","title":"About","text":"<p>This project is an experiment in open science and model development. We'll be live-blogging the process of building a new, state-of-the-art typhoid immune model for use in transmission modeling and vaccine schedule recommendations. Documentation will grow as the model stabilizes, and all code will be available in flight.</p> <p>Please follow along and don't hesitate to comment via github issues, or send me an email at mike-dot-famulare-at-gatesfoundation-dot-org.</p>"},{"location":"blog/","title":"Typhoid immune dynamics working notes","text":"<p>Blog to share musings, work in progress, etc to complement stand-alone Docs.</p>"},{"location":"blog/2025/03/13/what-do-i-look-for-from-vaccine-efficacy-studies-to-inform-model-development-draft/","title":"What do I look for from vaccine efficacy studies to inform model development? (DRAFT)","text":""},{"location":"blog/2025/03/17/hand-rolling-empirical-bayes-estimation-of-a-hierarchical-model-to-learn-how-it-works/","title":"Hand rolling empirical Bayes estimation of a hierarchical model to learn how it works","text":"<p>This is a quick experiment to teach myself if I can just use full likelihood optimization to get well-behaved empirical Bayes estimate of both the trial-level random effects and the metastudy group-level hyperparameters in a mixed model.</p> <p>Why? Because proper statisticians say you aren\u2019t supposed to use a full likelihood to estimate random effects and hyperparameters because it\u2019s biased for the group-level variance components, but how much does it matter for model fitting metastudy applications?</p> <p>I care because I like to use simple optimizations when initially calibrating models on the kind of strange data types I get from papers when I don\u2019t have the individual-level data. I want to better understand when I can take shortcuts and still get decent statistical properties during model development. Then, if doing the stats better proves to be important, relative to other limitations of the model, we can do better later.</p> <p>Also, I use packages to do mixed-effects modeling all the time, but I\u2019ve never worked out a non-Gaussian example. That is not a morally-sustainable position.</p> <p>What? Compare full maximum likelihood (ML) estimate where I jointly optimize over the subject-level random effects and the group level hyperparameters, vs the restricted maximum likelihood (REML) estimate where I first optimize only over the hyperparamaters and then find an empirical Bayes estimate of the random effects given the hyperparameters. For the best tight description of the two algorithms that I\u2019ve found, see this documentation for Estimating Parameters in Linear Mixed-Effects Models from The Mathworks.</p> <p>What did I learn? WHELP, it looks full likelihood optimization is just fine, at least for this example, which is on a relevant scale for a vaccine model building metastudy. (Of order 10 trial arms, with of order 100 subjects per arm, and binary outcomes.) I also learned that it was easy to implement the REML approach in this example. So, if it\u2019s also easy on the real calibration problem to come, I\u2019ll probably just do that.</p> <p>To learn more, and very quickly, about what I\u2019m trying to do, here\u2019s a useful chat log with ChatGPT4.5 to go along with this.</p> <p>What am I looking for from you? I\u2019ve learned a lot of stats over the last 15 years, but I\u2019m not trained as a statistician and I\u2019m always learning more. Please comment if you see anything you\u2019d like to correct or expand upon. Also, let me know if this was useful to you. Thanks!</p> <p>Note about how this post was generated. This post was generated directly from the commented R script using the <code>knitr::spin</code> functionality of <code>rmarkdown::render</code>. This gives all the advantages of scripts and r-markdown, without the disadvantages. Check out this blog post by Dean Attali to learn more.</p>"},{"location":"blog/2025/03/17/hand-rolling-empirical-bayes-estimation-of-a-hierarchical-model-to-learn-how-it-works/#setting-up-the-study","title":"Setting up the study","text":"<p>First, we set up a study with 10 trial arms and 100 people measured per arm. The group level is the ensemble of trial arms, and the individuals in this exmaple are the trial arms. The observations for each trial arm are zero or one for the outcome, and each arm has a true probability of the outcome drawn from a beta distribution for the ensemble of studies. Note that this isn\u2019t set up as real vaccine efficacy measurement. I\u2019m just interested in looking at cohort parameter estimation for now. VE would be a transform on that, if the arms were labeled by treatment vs control.</p> <pre><code># set up the environment\nlibrary(tidyverse)\nlibrary(rmutil)\nlibrary(stats4)\nlibrary(knitr)\n\n# set seed for reproducibility. Comment out to run many examples to see that this example is representative.\nset.seed(100)\n\n##simulate binomial draws from a beta random-effects model\n# typical example of a metastudy, 10 trials, ~100 subjects per trial\nn_trials = 10 # don't change! I hard-coded 10 later for dumb reasons w/r/t variable names in stats4::mle that I didn't feel like debugging.\nn_subjects=100 # you can change this if you want.\n\n# set up the measurement-level data frame\nsubjects = expand_grid(ID=1:n_trials,rep = 1:n_subjects)\n\n## draw probability of positive for each ID from a beta distribution\n\n# rmutil::betabinomial parameterization\nm=0.3\ns=8\n\n# rbeta parameterization\nalpha=m*s\nbeta=s-alpha\n\n# add true trial-level outcome probality to the subject data\nsubjects = subjects |&gt; left_join(\n  data.frame(ID=1:n_trials,p=rbeta(n_trials,shape1=alpha,shape2=beta)))\n\n# draw binomial samples for each subject\nsubjects = subjects |&gt; cbind(\n  data.frame(response=rbinom(n=nrow(subjects),size=1,prob=subjects$p)))\n\n# collapse the measurement-level data into subject level data for fitting later\nobserved = subjects |&gt; group_by(ID,p) |&gt;\n            summarize(n_pos=sum(response),\n                      n_trials=n(),\n                      p_hat = n_pos/n_trials)\n\nobserved |&gt; kable()\n</code></pre> ID p n_pos n_trials p_hat 1 0.2134503 22 100 0.22 2 0.3254404 34 100 0.34 3 0.2853022 27 100 0.27 4 0.4947419 48 100 0.48 5 0.3225656 29 100 0.29 6 0.3637010 49 100 0.49 7 0.2012123 23 100 0.23 8 0.4527466 45 100 0.45 9 0.1662158 17 100 0.17 10 0.2363248 34 100 0.34"},{"location":"blog/2025/03/17/hand-rolling-empirical-bayes-estimation-of-a-hierarchical-model-to-learn-how-it-works/#parameter-inference-with-the-full-likelihood","title":"Parameter inference with the full likelihood","text":"<p>The first approach I\u2019m considering is maximum likelihood estimation of both the population-level hyperparameters and the trial-level outcome probabilities. We can estimate both the MLE and the Wald confidence intervals from the variance-covariance matrix using <code>stats4::mle</code>. In the code chunk below, I define the likelihood function, run the optimization (using <code>method = 'L-BFGS-B</code> with appropriate bounds to respect parameter domains), and tidy up the results for display and plotting later.</p> <pre><code># define the negative log likelihood for the fully parameterized model: beta-distributed population + individial binomial probabilities\n# Note that I'm hardcoding data for this demo so I don't have to worry about passing data to mle later. This is for convenience.\nminus_log_lik = function(m=alpha/(alpha+beta),s=(alpha+beta),\n                         p1=observed$p[1],p2=observed$p[2],p3=observed$p[3],p4=observed$p[4], # there's surely a nicer way to do this...\n                         p5=observed$p[5],p6=observed$p[6],p7=observed$p[7],p8=observed$p[8],\n                         p9=observed$p[9],p10=observed$p[10]){\n  a = m*s\n  b = s-a\n  p =c(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10)\n\n  -sum(dbeta(x=p,shape1=a,shape2=b,log=TRUE) + dbinom(x=observed$n_pos,size=observed$n_trials,prob=p,log=TRUE))\n} \nminus_log_lik()\n\n# find the maximum likelihood estimate simulateously for both the trial-level random effects and the hyperparameters.\nmodel_lik = stats4::mle(minus_log_lik, start = list(m=0.5,s=10,p1=0.5,p2=0.5,p3=0.5,p4=0.5,\n                                                    p5=0.5,p6=0.5,p7=0.5,p8=0.5,p9=0.5,p10=0.5),\n                        method='L-BFGS-B',\n                        upper=c(0.99999,Inf,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999),\n                        lower=c(0.00001,0,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001))\nsummary(model_lik)\n\n# tidy up the results for display and later plotting\nfull_lik_params = data.frame(true=c(m=m,s=s,observed$p), estimate =coef(model_lik),  se = sqrt(diag(vcov(model_lik )))) |&gt;\n  mutate( z = (true-estimate)^2/se^2,\n          lower = estimate - 1.96*se, # wald confidence interval\n          upper = estimate + 1.96*se) |&gt;\n  rownames_to_column(var='param') |&gt;\n  select(param, everything()) |&gt; \n  mutate(param=factor(param,levels=c('m','s','p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'))) |&gt;\n  mutate(level=factor(c('group_mean','group_dispersion',rep('trial',10)))) |&gt;\n  mutate(param_index = 1:12)\n\nfull_lik_params\n\n##    param      true   estimate          se          z      lower      upper            level param_index\n## 1      m 0.3000000  0.3246235  0.02967484 0.68853213  0.2664609  0.3827862       group_mean           1\n## 2      s 8.0000000 32.0202634 19.93898104 1.45127465 -7.0601394 71.1006663 group_dispersion           2\n## 3     p1 0.2134503  0.2414595  0.04012803 0.48719936  0.1628086  0.3201105            trial           3\n## 4     p2 0.3254404  0.3337523  0.04203733 0.03909562  0.2513592  0.4161455            trial           4\n## 5     p3 0.2853022  0.2799146  0.04053223 0.01766756  0.2004715  0.3593578            trial           5\n## 6     p4 0.4947419  0.4414270  0.04786335 1.24076659  0.3476149  0.5352392            trial           6\n## 7     p5 0.3225656  0.2952969  0.04085350 0.44552396  0.2152241  0.3753698            trial           7\n## 8     p6 0.3637010  0.4491181  0.04839787 3.11484948  0.3542583  0.5439780            trial           8\n## 9     p7 0.2012123  0.2491503  0.04016259 1.42467515  0.1704316  0.3278690            trial           9\n## 10    p8 0.4527466  0.4183538  0.04634406 0.55074260  0.3275194  0.5091881            trial          10\n## 11    p9 0.1662158  0.2030039  0.04030446 0.83312302  0.1240072  0.2820006            trial          11\n## 12   p10 0.2363248  0.3337523  0.04203733 5.37146452  0.2513592  0.4161455            trial          12\n</code></pre>"},{"location":"blog/2025/03/17/hand-rolling-empirical-bayes-estimation-of-a-hierarchical-model-to-learn-how-it-works/#parameter-inference-with-reml-and-empirical-bayes","title":"Parameter inference with REML and empirical Bayes","text":"<p>Before looking to closely at the results, let\u2019s look at the other (statistician-preferred) approach of estimating the hyperparameters first with the trial-level random effects integrated out, and then estimating the trial-level random effects given the hyperparameter MLEs.</p> <p>For the beta-binomial model, the restricted likelihood is just the analytic betabinomial distribution, which I wrap into a negative log likelhood for fitting.</p> <pre><code># hyperparameter likelihood\nminus_log_REML = function(m=alpha/(alpha+beta),s=(alpha+beta)){\n  -sum(rmutil::dbetabinom(y=observed$n_pos,size=observed$n_trials,m=m,s=s,log=TRUE))\n}\nminus_log_REML()\n\n# hyperparameter MLE\nmodel_REML = stats4::mle(minus_log_REML, start = list(m=0.5,s=1),\n            method='L-BFGS-B',\n            upper=c(0.99999,Inf),\n            lower=c(0.00001,0))\n\nsummary(model_REML)\n</code></pre> <p>Next, given the MLEs for the hyperparameters, I estimate the trial-level outcome probabilities and tidy up all the results.</p> <pre><code># empirical Bayes likelihood for the individual-level random effects. Plug in MLE of the hyperparameters.\nminus_log_REML_p = function(p1=observed$p[1],p2=observed$p[2],p3=observed$p[3],p4=observed$p[4], # there's probably a nicer way to do this...\n                            p5=observed$p[5],p6=observed$p[6],p7=observed$p[7],p8=observed$p[8],\n                            p9=observed$p[9],p10=observed$p[10]){\n\n  a = coef(model_REML)[1]*coef(model_REML)[2]\n  b = coef(model_REML)[2]-a\n  p =c(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10)\n\n  -sum(dbeta(x=p,shape1=a,shape2=b,log=TRUE) + dbinom(x=observed$n_pos,size=observed$n_trials,prob=p,log=TRUE))\n\n}\nminus_log_REML_p()\n\n# estimate the trial-level probabilities\nmodel_REML_p = stats4::mle(minus_log_REML_p, start = list(p1=0.5,p2=0.5,p3=0.5,p4=0.5,\n                                                        p5=0.5,p6=0.5,p7=0.5,p8=0.5,p9=0.5,p10=0.5),\n                         method='L-BFGS-B',\n                         upper=c(0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999,0.99999),\n                         lower=c(0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001,0.00001))\n\nsummary(model_REML_p)\n\n# and tidy up the results\nREML_params=data.frame(true=c(m=m,s=s,observed$p), estimate =c(coef(model_REML),coef(model_REML_p)), se = c(sqrt(diag(vcov(model_REML))),sqrt(diag(vcov(model_REML_p))))) |&gt;\n  mutate( z = (true-estimate)^2/se^2,\n          lower = estimate - 1.96*se,\n          upper = estimate + 1.96*se) |&gt;\n  rownames_to_column(var='param') |&gt;\n  select(param, everything()) |&gt; \n  mutate(param=factor(param,levels=c('m','s','p1','p2','p3','p4','p5','p6','p7','p8','p9','p10'))) |&gt;\n  mutate(level=factor(c('group_mean','group_dispersion',rep('trial',10)))) |&gt;\n  mutate(param_index = 1:12)\n\nREML_params\n\n##    param      true   estimate          se          z      lower      upper            level param_index\n## 1      m 0.3000000  0.3280964  0.03351673 0.70271450  0.2624036  0.3937892       group_mean           1\n## 2      s 8.0000000 23.1436114 12.56215846 1.45321669 -1.4782192 47.7654420 group_dispersion           2\n## 3     p1 0.2134503  0.2360292  0.03858028 0.34251204  0.1604119  0.3116466            trial           3\n## 4     p2 0.3254404  0.3350849  0.04288521 0.05057560  0.2510299  0.4191399            trial           4\n## 5     p3 0.2853022  0.2773025  0.04067250 0.03868527  0.1975843  0.3570206            trial           5\n## 6     p4 0.4947419  0.4506498  0.04520559 0.95134048  0.3620469  0.5392528            trial           6\n## 7     p5 0.3225656  0.2938117  0.04138481 0.48273865  0.2126975  0.3749259            trial           7\n## 8     p6 0.3637010  0.4589045  0.04527371 4.42194639  0.3701680  0.5476410            trial           8\n## 9     p7 0.2012123  0.2442839  0.03903654 1.21741661  0.1677723  0.3207956            trial           9\n## 10    p8 0.4527466  0.4258858  0.04492556 0.35748004  0.3378317  0.5139399            trial          10\n## 11    p9 0.1662158  0.1947565  0.03597917 0.62925532  0.1242373  0.2652756            trial          11\n## 12   p10 0.2363248  0.3350849  0.04288521 5.30331730  0.2510299  0.4191399            trial          12\n</code></pre>"},{"location":"blog/2025/03/17/hand-rolling-empirical-bayes-estimation-of-a-hierarchical-model-to-learn-how-it-works/#results","title":"Results","text":"<p>Now that we\u2019ve run both estimation processes, we can compare the results to each other and the underlying simulated truth.</p> <pre><code>ggplot() +\n  geom_point(data=full_lik_params,aes(x=param_index,y=estimate),color='red') +\n  geom_segment(data=full_lik_params,aes(x=param_index,y=lower,yend=upper,group=param),color='red') +\n  geom_point(data=REML_params,aes(x=param_index+0.1,y=estimate),color='blue') +\n  geom_segment(data=REML_params,aes(x=param_index+0.1,y=lower,yend=upper,group=param),color='blue') +\n  geom_point(data=full_lik_params,aes(x=param_index-0.1,y=true)) +\n  theme_bw()+\n  facet_wrap('level',scales='free') +\n  scale_x_continuous(breaks=seq(1:12),labels=levels(full_lik_params$param),minor_breaks = NULL) +\n  xlab('') +\n  geom_text(data=data.frame(param_index=rep(1.945,3),y=full_lik_params$upper[2]*c(0.95,0.85,0.75),label=c('truth','full likelihood','REML'),level=rep('group_dispersion',3)),\n            aes(x=param_index,y=y,label=label),color=c('black','red','blue'))\n</code></pre> <p></p> <p>In this example, the results are qualitatively similar.</p> <ul> <li> <p>Nominal 95% confidence interval coverage is acceptable for my     purposes for both,</p> <ul> <li>especially as Wald intervals are known to be too     narrow     and don\u2019t enforce that the dispersion hyperparameter must be     positive because I worked on the outcome scale and not the link     scale.</li> </ul> </li> <li> <p>The trial-level effect estimates and the group-level mean estimates     are nearly identical.</p> </li> <li> <p>The group-level dispersion parameter is biased high with the full     likelihood vs the REML estimate, as expected from the stats theory,     and in this case a bit wider.</p> </li> </ul>"},{"location":"blog/2025/03/17/hand-rolling-empirical-bayes-estimation-of-a-hierarchical-model-to-learn-how-it-works/#my-take-away","title":"My take-away","text":"<p>The most interesting parameters for the analogous problem in the immunity modeling building to come are the group-level mean and trial-level individual effects, both of which are estimated with similar quality regardless of the method. The group-level dispersion is the least relevant parameter for that activity, and so I take away that I\u2019m probably fine to do whatever is easiest to implement.</p> <p>And regardless, this will be a great place to engage with some peer review after the model is prototyped, so that we can do better if needed.</p> <p>Thanks for reading!</p>"},{"location":"blog/2025/03/11/what-is-immunity-really-draft/","title":"What is immunity, really? (DRAFT)","text":"<p>The first thing anyone learns about epi modeling is how to represent people as \"immune\" or not. Is anyone either completely immune or not to anything? NO! Let's flesh that out and think through what it means to us, as modelers...</p> <p></p> <p>To-do:</p> <ul> <li> <p>talk through different concepts of immunity</p> <ul> <li> <p>binary as an approximation</p> </li> <li> <p>immune as an immunologist vs as an epidemiologist or vaccinologist</p> </li> </ul> </li> <li> <p>effectiveness vs efficacy, as relevant to model building</p> </li> <li> <p>waning</p> <ul> <li>effectiveness or correlate?</li> </ul> </li> <li> <p>sequential response</p> </li> <li> <p>hierarchy of complexity</p> </li> <li> <p>what to do next?</p> </li> </ul>"},{"location":"blog/2025/03/13/why-not-use-off-the-shelf-pkpd-modeling-software-draft/","title":"Why not use off-the-shelf PK/PD modeling software? (DRAFT)","text":""},{"location":"docs/overview/","title":"Overview","text":"<p>This Docs section contains stand-alone documentation of the science and software supporting IDM's new typhoid immunity model. </p> <p>All data, code, writing, and results associated with this project are available on Github at famulare/typhoid-immune-dynamics.</p> <p>Major components include:</p> <ul> <li> <p>Literature Review to describe the questions we want the model to help answer and data required to fit the model.</p> </li> <li> <p>Descriptions of the Model Architecture that document the mathematics and software design.</p> </li> <li> <p>Calibration to estimate model parameters from data.</p> </li> <li> <p>Model Diagnostics to quantify goodness of fit and identify issues with the model, data, or both.</p> </li> <li> <p>and Doing Science with the model.</p> </li> </ul> <p>Click through the menu for the content.</p> <p>The Blog exists share musings, work in progress, etc that complement these Docs.</p>"},{"location":"docs/Literature%20Review/typhoid-vaccine-efficacy/","title":"Typhoid Conjugate Vaccine Efficacy","text":""},{"location":"docs/Model%20Architecture/Immune-model-mathematical-description/","title":"Immunity Model: Mathematical Description","text":""},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/calibration/","title":"Calibration","text":""},{"location":"blog/category/self-study/","title":"Self-study","text":""},{"location":"blog/category/immunity-models/","title":"Immunity Models","text":""},{"location":"blog/category/literature-review/","title":"Literature Review","text":""},{"location":"blog/category/software-architecture/","title":"Software Architecture","text":""}]}